{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7892eaab-bd30-41f8-9ddc-ba7b618ead3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracted_files/Engineering CVs/Christopher McComb.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Christopher McComb.pdf\n",
      "extracted_files/Engineering CVs/PANAYIOTIS (PANOS) MOUTIS.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/PANAYIOTIS (PANOS) MOUTIS.pdf\n",
      "400 Unable to submit request because the input token count is 63063 but model only supports up to 32766. Reduce the input token count and try again. You can also use the CountTokens API to calculate prompt token count and billable characters. Learn more: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models\n",
      "400 Unable to submit request because the input token count is 35429 but model only supports up to 32766. Reduce the input token count and try again. You can also use the CountTokens API to calculate prompt token count and billable characters. Learn more: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models\n",
      "extracted_files/Engineering CVs/Matteo Pozzi .pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Matteo Pozzi .pdf\n",
      "extracted_files/Engineering CVs/DAVID R. ROUNCE, Ph.D..pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/DAVID R. ROUNCE, Ph.D..pdf\n",
      "extracted_files/Engineering CVs/DAVID R. ROUNCE, Ph.D..docx\n",
      "Renamed file to: extracted_files/Engineering CVs/DAVID R. ROUNCE, Ph.D..docx\n",
      "extracted_files/Engineering CVs/Dr. Joanne C. Peca.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Dr. Joanne C. Peca.pdf\n",
      "Invalid control character at: line 61 column 103 (char 1575)\n",
      "extracted_files/Engineering CVs/KAI YU.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/KAI YU.pdf\n",
      "400 Unable to submit request because the input token count is 58769 but model only supports up to 32766. Reduce the input token count and try again. You can also use the CountTokens API to calculate prompt token count and billable characters. Learn more: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models\n",
      "extracted_files/Engineering CVs/Marvin Sirbu.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Marvin Sirbu.pdf\n",
      "extracted_files/Engineering CVs/MARVIN SIRBU.docx\n",
      "Renamed file to: extracted_files/Engineering CVs/MARVIN SIRBU.docx\n",
      "400 Unable to submit request because the input token count is 41357 but model only supports up to 32766. Reduce the input token count and try again. You can also use the CountTokens API to calculate prompt token count and billable characters. Learn more: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models\n",
      "extracted_files/Engineering CVs/L. Richard Carley.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/L. Richard Carley.pdf\n",
      "extracted_files/Engineering CVs/Mark M. Budnik.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Mark M. Budnik.pdf\n",
      "extracted_files/Engineering CVs/Albert A. Presto.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Albert A. Presto.pdf\n",
      "extracted_files/Engineering CVs/Jia, Limin.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Jia, Limin.pdf\n",
      "extracted_files/Engineering CVs/Suresh Kumar, Swarun Kumar.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Suresh Kumar, Swarun Kumar.pdf\n",
      "400 Unable to submit request because the input token count is 33596 but model only supports up to 32766. Reduce the input token count and try again. You can also use the CountTokens API to calculate prompt token count and billable characters. Learn more: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models\n",
      "extracted_files/Engineering CVs/Yorie Nakahira.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Yorie Nakahira.pdf\n",
      "extracted_files/Engineering CVs/Rosalyn D Abbott, Ph.D..pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Rosalyn D Abbott, Ph.D..pdf\n",
      "400 Unable to submit request because the input token count is 43852 but model only supports up to 32766. Reduce the input token count and try again. You can also use the CountTokens API to calculate prompt token count and billable characters. Learn more: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models\n",
      "extracted_files/Engineering CVs/Fethiye Ozis.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Fethiye Ozis.pdf\n",
      "extracted_files/Engineering CVs/Fethiye  Ozis, PhD, PE.docx\n",
      "Renamed file to: extracted_files/Engineering CVs/Fethiye  Ozis, PhD, PE.docx\n",
      "400 Unable to submit request because the input token count is 105902 but model only supports up to 32766. Reduce the input token count and try again. You can also use the CountTokens API to calculate prompt token count and billable characters. Learn more: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models\n",
      "extracted_files/Engineering CVs/ZIAD YOUSSFI, PHD.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/ZIAD YOUSSFI, PHD.pdf\n",
      "extracted_files/Engineering CVs/Carl Damon Laird.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Carl Damon Laird.pdf\n",
      "extracted_files/Engineering CVs/Hironobu MURATA, Ph.D..pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Hironobu MURATA, Ph.D..pdf\n",
      "Expecting ',' delimiter: line 64 column 4 (char 3769)\n",
      "Expecting property name enclosed in double quotes: line 62 column 1 (char 3877)\n",
      "extracted_files/Engineering CVs/Kathy Lachenauer.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Kathy Lachenauer.pdf\n",
      "extracted_files/Engineering CVs/Levent Burak Kara.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Levent Burak Kara.pdf\n",
      "extracted_files/Engineering CVs/Levent Burak Kara.docx\n",
      "Renamed file to: extracted_files/Engineering CVs/Levent Burak Kara.docx\n",
      "extracted_files/Engineering CVs/Timothy X Brown.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Timothy X Brown.pdf\n",
      "extracted_files/Engineering CVs/Timothy X Brown.doc\n",
      "Renamed file to: extracted_files/Engineering CVs/Timothy X Brown.doc\n",
      "400 Unable to submit request because the input token count is 133627 but model only supports up to 32766. Reduce the input token count and try again. You can also use the CountTokens API to calculate prompt token count and billable characters. Learn more: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models\n",
      "Invalid control character at: line 13 column 22 (char 313)\n",
      "extracted_files/Engineering CVs/Mohammad F. ISLAM.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Mohammad F. ISLAM.pdf\n",
      "extracted_files/Engineering CVs/Gregory R. Ganger.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Gregory R. Ganger.pdf\n",
      "extracted_files/Engineering CVs/Noa Marom.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Noa Marom.pdf\n",
      "400 Unable to submit request because the input token count is 84672 but model only supports up to 32766. Reduce the input token count and try again. You can also use the CountTokens API to calculate prompt token count and billable characters. Learn more: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models\n",
      "extracted_files/Engineering CVs/Pedro J. Bustamante.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Pedro J. Bustamante.pdf\n",
      "extracted_files/Engineering CVs/Harper, Corey.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Harper, Corey.pdf\n",
      "extracted_files/Engineering CVs/Harper, Corey.doc\n",
      "Renamed file to: extracted_files/Engineering CVs/Harper, Corey.doc\n",
      "extracted_files/Engineering CVs/Dr. Emmanuel Ndashimye.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Dr. Emmanuel Ndashimye.pdf\n",
      "extracted_files/Engineering CVs/Aditya S. Khair.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Aditya S. Khair.pdf\n",
      "extracted_files/Engineering CVs/Kate S. Whitefoot.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Kate S. Whitefoot.pdf\n",
      "extracted_files/Engineering CVs/Brandon Lucia.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Brandon Lucia.pdf\n",
      "extracted_files/Engineering CVs/Brandon Lucia.doc\n",
      "Renamed file to: extracted_files/Engineering CVs/Brandon Lucia.doc\n",
      "extracted_files/Engineering CVs/Brandon Lucia.docx\n",
      "Renamed file to: extracted_files/Engineering CVs/Brandon Lucia.docx\n",
      "extracted_files/Engineering CVs/Yu-li Wang.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Yu-li Wang.pdf\n",
      "extracted_files/Engineering CVs/Giulia Cecilia Fanti.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Giulia Cecilia Fanti.pdf\n",
      "400 Unable to submit request because the input token count is 59496 but model only supports up to 32766. Reduce the input token count and try again. You can also use the CountTokens API to calculate prompt token count and billable characters. Learn more: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models\n",
      "400 Unable to submit request because the input token count is 59496 but model only supports up to 32766. Reduce the input token count and try again. You can also use the CountTokens API to calculate prompt token count and billable characters. Learn more: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models\n",
      "400 Unable to submit request because the input token count is 59496 but model only supports up to 32766. Reduce the input token count and try again. You can also use the CountTokens API to calculate prompt token count and billable characters. Learn more: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models\n",
      "extracted_files/Engineering CVs/Hanan Hibshi.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Hanan Hibshi.pdf\n",
      "extracted_files/Engineering CVs/Martin Saint.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Martin Saint.pdf\n",
      "extracted_files/Engineering CVs/Gladys M. Mercier.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Gladys M. Mercier.pdf\n",
      "extracted_files/Engineering CVs/Barry Gordon Rawn.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Barry Gordon Rawn.pdf\n",
      "Expecting value: line 1 column 1 (char 0)\n",
      "400 Unable to submit request because the input token count is 39873 but model only supports up to 32766. Reduce the input token count and try again. You can also use the CountTokens API to calculate prompt token count and billable characters. Learn more: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models\n",
      "extracted_files/Engineering CVs/Noelia GRANDE GUTI´ERREZ, Ph.D..pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Noelia GRANDE GUTI´ERREZ, Ph.D..pdf\n",
      "Expecting value: line 1 column 1 (char 0)\n",
      "extracted_files/Engineering CVs/Dr. Hamish Gordon.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Dr. Hamish Gordon.pdf\n",
      "extracted_files/Engineering CVs/Rohit Negi.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Rohit Negi.pdf\n",
      "extracted_files/Engineering CVs/Rachelle (Palchesko) Simko, Ph.D..pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Rachelle (Palchesko) Simko, Ph.D..pdf\n",
      "extracted_files/Engineering CVs/Rachelle (Palchesko) Simko, Ph.D..docx\n",
      "Renamed file to: extracted_files/Engineering CVs/Rachelle (Palchesko) Simko, Ph.D..docx\n",
      "extracted_files/Engineering CVs/Rachelle (Palchesko) Simko, Ph.D..docx\n",
      "Renamed file to: extracted_files/Engineering CVs/Rachelle (Palchesko) Simko, Ph.D..docx\n",
      "extracted_files/Engineering CVs/Assane Gueye.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Assane Gueye.pdf\n",
      "extracted_files/Engineering CVs/Jonathan A. Malen.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Jonathan A. Malen.pdf\n",
      "extracted_files/Engineering CVs/Matthew A Smith, PhD.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Matthew A Smith, PhD.pdf\n",
      "extracted_files/Engineering CVs/Grover, Pulkit.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Grover, Pulkit.pdf\n",
      "extracted_files/Engineering CVs/Valerie J. Karplus.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Valerie J. Karplus.pdf\n",
      "400 Unable to submit request because the input token count is 33645 but model only supports up to 32766. Reduce the input token count and try again. You can also use the CountTokens API to calculate prompt token count and billable characters. Learn more: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models\n",
      "400 Unable to submit request because the input token count is 33645 but model only supports up to 32766. Reduce the input token count and try again. You can also use the CountTokens API to calculate prompt token count and billable characters. Learn more: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models\n",
      "400 Unable to submit request because the input token count is 33645 but model only supports up to 32766. Reduce the input token count and try again. You can also use the CountTokens API to calculate prompt token count and billable characters. Learn more: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models\n",
      "extracted_files/Engineering CVs/Ding Zhao.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Ding Zhao.pdf\n",
      "extracted_files/Engineering CVs/Sarah Jane Christian, Ph.D., P.E..pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Sarah Jane Christian, Ph.D., P.E..pdf\n",
      "extracted_files/Engineering CVs/William Nace.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/William Nace.pdf\n",
      "extracted_files/Engineering CVs/Carmel Majidi.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Carmel Majidi.pdf\n",
      "400 Unable to submit request because the input token count is 32769 but model only supports up to 32766. Reduce the input token count and try again. You can also use the CountTokens API to calculate prompt token count and billable characters. Learn more: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models\n",
      "extracted_files/Engineering CVs/Edith Talina Luhanga.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Edith Talina Luhanga.pdf\n",
      "extracted_files/Engineering CVs/Edith Talina Luhanga.docx\n",
      "Renamed file to: extracted_files/Engineering CVs/Edith Talina Luhanga.docx\n",
      "extracted_files/Engineering CVs/GUANNAN QU.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/GUANNAN QU.pdf\n",
      "extracted_files/Engineering CVs/James W. Schneider.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/James W. Schneider.pdf\n",
      "extracted_files/Engineering CVs/Elizabeth Wayne.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Elizabeth Wayne.pdf\n",
      "extracted_files/Engineering CVs/Sokalski, Vincent.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Sokalski, Vincent.pdf\n",
      "extracted_files/Engineering CVs/Yuejie Chi.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Yuejie Chi.pdf\n",
      "extracted_files/Engineering CVs/Yuejie Chi.docx\n",
      "Renamed file to: extracted_files/Engineering CVs/Yuejie Chi.docx\n",
      "extracted_files/Engineering CVs/Wui Yarn Daphne Chan.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Wui Yarn Daphne Chan.pdf\n",
      "extracted_files/Engineering CVs/Philip Koopman.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Philip Koopman.pdf\n",
      "extracted_files/Engineering CVs/George Amvrosiadis.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/George Amvrosiadis.pdf\n",
      "Extra data: line 17 column 1 (char 202)\n",
      "extracted_files/Engineering CVs/Lujo Bauer.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Lujo Bauer.pdf\n",
      "Invalid control character at: line 5 column 13 (char 52)\n",
      "extracted_files/Engineering CVs/Kelvin B. Gregory, Ph.D..pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Kelvin B. Gregory, Ph.D..pdf\n",
      "Expecting value: line 1 column 1 (char 0)\n",
      "extracted_files/Engineering CVs/DAVID VERNON.doc\n",
      "Renamed file to: extracted_files/Engineering CVs/DAVID VERNON.doc\n",
      "extracted_files/Engineering CVs/Qing Li.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Qing Li.pdf\n",
      "extracted_files/Engineering CVs/Bryan Parno.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Bryan Parno.pdf\n",
      "extracted_files/Engineering CVs/Kaushik Dayal.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Kaushik Dayal.pdf\n",
      "extracted_files/Engineering CVs/Kaushik Dayal.doc\n",
      "Renamed file to: extracted_files/Engineering CVs/Kaushik Dayal.doc\n",
      "extracted_files/Engineering CVs/Patjanaporn “Sang” Chalacheva.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Patjanaporn “Sang” Chalacheva.pdf\n",
      "extracted_files/Engineering CVs/Patjanaporn “Sang” Chalacheva.doc\n",
      "Renamed file to: extracted_files/Engineering CVs/Patjanaporn “Sang” Chalacheva.doc\n",
      "extracted_files/Engineering CVs/Marc P. Dandin.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Marc P. Dandin.pdf\n",
      "extracted_files/Engineering CVs/Eni Halilaj.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Eni Halilaj.pdf\n",
      "extracted_files/Engineering CVs/Eni Halilaj.docx\n",
      "Renamed file to: extracted_files/Engineering CVs/Eni Halilaj.docx\n",
      "extracted_files/Engineering CVs/Erica R.H. Fuchs.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Erica R.H. Fuchs.pdf\n",
      "extracted_files/Engineering CVs/Joshi, Gauri.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Joshi, Gauri.pdf\n",
      "extracted_files/Engineering CVs/Gauri Joshi.docx\n",
      "Renamed file to: extracted_files/Engineering CVs/Gauri Joshi.docx\n",
      "extracted_files/Engineering CVs/Gauri Joshi.doc\n",
      "Renamed file to: extracted_files/Engineering CVs/Gauri Joshi.doc\n",
      "extracted_files/Engineering CVs/Pedro Ferreira.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Pedro Ferreira.pdf\n",
      "extracted_files/Engineering CVs/Vanessa Hung-Chu Chen.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Vanessa Hung-Chu Chen.pdf\n",
      "extracted_files/Engineering CVs/Keith E. Cook, PhD.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Keith E. Cook, PhD.pdf\n",
      "extracted_files/Engineering CVs/Edwin MUGUME.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Edwin MUGUME.pdf\n",
      "Extra data: line 33 column 1 (char 767)\n",
      "extracted_files/Engineering CVs/Maarten P. de Boer.pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Maarten P. de Boer.pdf\n",
      "extracted_files/Engineering CVs/Grigorios Panagakos, Ph.D..pdf\n",
      "Renamed file to: extracted_files/Engineering CVs/Grigorios Panagakos, Ph.D..pdf\n",
      "400 Unable to submit request because the input token count is 35659 but model only supports up to 32766. Reduce the input token count and try again. You can also use the CountTokens API to calculate prompt token count and billable characters. Learn more: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models\n",
      "400 Unable to submit request because the input token count is 67406 but model only supports up to 32766. Reduce the input token count and try again. You can also use the CountTokens API to calculate prompt token count and billable characters. Learn more: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models\n",
      "Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 106\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m \u001b[43mprocess_resumes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mextracted_files\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[22], line 89\u001b[0m, in \u001b[0;36mprocess_resumes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;66;03m# For .docx and .doc\u001b[39;00m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;66;03m#text = parse_docx(file)\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Extract fields\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m fields \u001b[38;5;241m=\u001b[39m \u001b[43mextract_fields\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# Print or save the extracted fields\u001b[39;00m\n\u001b[1;32m     92\u001b[0m   \u001b[38;5;66;03m# Or save to a database/file\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfields\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "Cell \u001b[0;32mIn[22], line 58\u001b[0m, in \u001b[0;36mextract_fields\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     45\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124mExtract the following fields from the resume text:\u001b[39m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124m1. Full Name\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Make API request\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     61\u001b[0m response\u001b[38;5;241m=\u001b[39mjson\u001b[38;5;241m.\u001b[39mloads(response)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/vertexai/generative_models/_generative_models.py:596\u001b[0m, in \u001b[0;36m_GenerativeModel.generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, tools, tool_config, stream)\u001b[0m\n\u001b[1;32m    588\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_content_streaming(\n\u001b[1;32m    589\u001b[0m         contents\u001b[38;5;241m=\u001b[39mcontents,\n\u001b[1;32m    590\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    593\u001b[0m         tool_config\u001b[38;5;241m=\u001b[39mtool_config,\n\u001b[1;32m    594\u001b[0m     )\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 596\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[43msafety_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafety_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtool_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtool_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/vertexai/generative_models/_generative_models.py:711\u001b[0m, in \u001b[0;36m_GenerativeModel._generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, tools, tool_config)\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generates content.\u001b[39;00m\n\u001b[1;32m    687\u001b[0m \n\u001b[1;32m    688\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;124;03m    A single GenerationResponse object\u001b[39;00m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    704\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_request(\n\u001b[1;32m    705\u001b[0m     contents\u001b[38;5;241m=\u001b[39mcontents,\n\u001b[1;32m    706\u001b[0m     generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    709\u001b[0m     tool_config\u001b[38;5;241m=\u001b[39mtool_config,\n\u001b[1;32m    710\u001b[0m )\n\u001b[0;32m--> 711\u001b[0m gapic_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prediction_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_response(gapic_response)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/aiplatform_v1beta1/services/prediction_service/client.py:2280\u001b[0m, in \u001b[0;36mPredictionServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   2277\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m   2279\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m-> 2280\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2281\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2283\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2285\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2287\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m   2288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/gapic_v1/method.py:113\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, *args, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m     metadata\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata)\n\u001b[1;32m    111\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m metadata\n\u001b[0;32m--> 113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:65\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(callable_)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21merror_remapped_callable\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/grpc/_channel.py:1173\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m   1162\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1163\u001b[0m     request: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1168\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1169\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m   1170\u001b[0m     (\n\u001b[1;32m   1171\u001b[0m         state,\n\u001b[1;32m   1172\u001b[0m         call,\n\u001b[0;32m-> 1173\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_blocking\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/grpc/_channel.py:1157\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._blocking\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1141\u001b[0m state\u001b[38;5;241m.\u001b[39mtarget \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_target)\n\u001b[1;32m   1142\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_channel\u001b[38;5;241m.\u001b[39msegregated_call(\n\u001b[1;32m   1143\u001b[0m     cygrpc\u001b[38;5;241m.\u001b[39mPropagationConstants\u001b[38;5;241m.\u001b[39mGRPC_PROPAGATE_DEFAULTS,\n\u001b[1;32m   1144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context,\n\u001b[1;32m   1156\u001b[0m )\n\u001b[0;32m-> 1157\u001b[0m event \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1158\u001b[0m _handle_event(event, state, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_deserializer)\n\u001b[1;32m   1159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m state, call\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:367\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:188\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:182\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:78\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._latent_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:61\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._internal_latent_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:42\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import fitz  # PyMuPDF\n",
    "import docx  # python-docx\n",
    "import requests  # To call the AI API\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "from vertexai.preview.generative_models import (\n",
    "    GenerationConfig,\n",
    "    GenerativeModel,\n",
    ")\n",
    "\n",
    "\n",
    "generation_config = GenerationConfig(\n",
    "    temperature=0,\n",
    "    max_output_tokens=8192,\n",
    ")\n",
    "model = GenerativeModel(\"gemini-pro\")\n",
    "\n",
    "\n",
    "\n",
    "# Function to parse PDF files\n",
    "def parse_pdf(file_path):\n",
    "    text = \"\"\n",
    "    with fitz.open(file_path) as doc:\n",
    "        for page in doc:\n",
    "            text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# Function to parse DOCX files\n",
    "def parse_docx(file_path):\n",
    "    text = \"\"\n",
    "    doc = docx.Document(file_path)\n",
    "    for para in doc.paragraphs:\n",
    "        text += para.text + \"\\n\"\n",
    "    return text\n",
    "\n",
    "# Function to extract fields from text using Gen AI API\n",
    "def extract_fields(text):\n",
    "    # Replace this URL with your Gen AI API endpoint\n",
    "    \n",
    "   \n",
    "    # Prompt for consistent output format\n",
    "    prompt = f\"\"\"\n",
    "    Extract the following fields from the resume text:\n",
    "    1. Full Name\n",
    "    2. Contact Information: Phone number, Email address, LinkedIn profile (if available)\n",
    "    3. Address: City and state\n",
    "    4. Education: Degrees obtained, Institutions attended, Graduation years\n",
    "\n",
    "    Format the output as a JSON text that can be used to convert to object using json.load() with the keys: 'name', 'contact', 'address', 'education'.\n",
    "    Resume text:\n",
    "    {text}\n",
    "    \"\"\"\n",
    "   \n",
    "    # Make API request\n",
    "    response = model.generate_content(prompt).text.replace('json','').replace(\"```\",'')\n",
    "    \n",
    "    \n",
    "    response=json.loads(response)\n",
    "    return response\n",
    "\n",
    "# Function to rename file based on last name and first name\n",
    "def rename_file(file_path, full_name):\n",
    "    # Split full name into last name and first name\n",
    "    \n",
    "    new_file_name = f\"{full_name}{Path(file_path).suffix}\"\n",
    "\n",
    "    new_file_path = Path(file_path).parent / new_file_name\n",
    "    print(new_file_path)\n",
    "    os.rename(file_path, new_file_path)\n",
    "    return new_file_path\n",
    "# Return original path if name is not in expected format\n",
    "\n",
    "# Main function to process resumes\n",
    "def process_resumes(directory):\n",
    "    for file in Path(directory).rglob(\"*\"):\n",
    "        try:\n",
    "            if file.suffix in [\".pdf\", \".docx\", \".doc\"]:\n",
    "                if file.suffix == \".pdf\":\n",
    "                    text = parse_pdf(file)\n",
    "                else:\n",
    "                    pass\n",
    "                    # For .docx and .doc\n",
    "                    #text = parse_docx(file)\n",
    "\n",
    "                # Extract fields\n",
    "                fields = extract_fields(text)\n",
    "\n",
    "                # Print or save the extracted fields\n",
    "                  # Or save to a database/file\n",
    "                \n",
    "                with open(f\"json/{fields.get('name')}.json\", 'w') as f:\n",
    "                   json.dump(fields, f, indent=4)\n",
    "                # # Rename the file\n",
    "                renamed_file_path = rename_file(file, fields.get('name'))\n",
    "                #renamed_file_path = rename_file(file, fields.get('name'))\n",
    "                #renamed_file_path=file\n",
    "                print(f\"Renamed file to: {renamed_file_path}\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "\n",
    "# Example usage\n",
    "process_resumes(\"extracted_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ab3b85-1cad-4cd4-9c67-d8fcd6f94a4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import fitz  # PyMuPDF\n",
    "import docx  # python-docx\n",
    "import requests  # To call the AI API\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3de26d-cf9e-42cb-be0d-bbdd69c98dc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45318af-8f0e-4448-b54f-1284bcb32c24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m118",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m118"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
