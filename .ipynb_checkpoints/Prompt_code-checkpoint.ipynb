{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7892eaab-bd30-41f8-9ddc-ba7b618ead3e",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 74)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m<tokenize>:74\u001b[0;36m\u001b[0m\n\u001b[0;31m    return file_path  # Return original path if name is not in expected format\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import fitz  # PyMuPDF\n",
    "import docx  # python-docx\n",
    "import requests  # To call the AI API\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "from vertexai.preview.generative_models import (\n",
    "    GenerationConfig,\n",
    "    GenerativeModel,\n",
    ")\n",
    "\n",
    "\n",
    "generation_config = GenerationConfig(\n",
    "    temperature=0,\n",
    "    max_output_tokens=8192,\n",
    ")\n",
    "model = GenerativeModel(\"gemini-pro\")\n",
    "\n",
    "\n",
    "\n",
    "# Function to parse PDF files\n",
    "def parse_pdf(file_path):\n",
    "    text = \"\"\n",
    "    with fitz.open(file_path) as doc:\n",
    "        for page in doc:\n",
    "            text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# Function to parse DOCX files\n",
    "def parse_docx(file_path):\n",
    "    text = \"\"\n",
    "    doc = docx.Document(file_path)\n",
    "    for para in doc.paragraphs:\n",
    "        text += para.text + \"\\n\"\n",
    "    return text\n",
    "\n",
    "# Function to extract fields from text using Gen AI API\n",
    "def extract_fields(text):\n",
    "    # Replace this URL with your Gen AI API endpoint\n",
    "    \n",
    "   \n",
    "    # Prompt for consistent output format\n",
    "    prompt = f\"\"\"\n",
    "    Extract the following fields from the resume text:\n",
    "    1. Full Name\n",
    "    2. Contact Information: Phone number, Email address, LinkedIn profile (if available)\n",
    "    3. Address: City and state\n",
    "    4. Education: Degrees obtained, Institutions attended, Graduation years\n",
    "\n",
    "    Format the output as a JSON text that can be used to convert to object using json.load() with the keys: 'name', 'contact', 'address', 'education'.\n",
    "    Resume text:\n",
    "    {text}\n",
    "    \"\"\"\n",
    "   \n",
    "    # Make API request\n",
    "    response = model.generate_content(prompt).text.replace('json','').replace(\"```\",'')\n",
    "    \n",
    "    print(response)\n",
    "    response=json.loads(response)\n",
    "    return response\n",
    "\n",
    "# Function to rename file based on last name and first name\n",
    "def rename_file(file_path, full_name):\n",
    "    # Split full name into last name and first name\n",
    "    \n",
    "    new_file_name = f\"{full_name}{Path(file_path).suffix}\"\n",
    "\n",
    "    new_file_path = Path(file_path).parent / new_file_name\n",
    "    print(new_file_path)\n",
    "    os.rename(file_path, new_file_path)\n",
    "    return new_file_path\n",
    "# Return original path if name is not in expected format\n",
    "\n",
    "# Main function to process resumes\n",
    "def process_resumes(directory):\n",
    "    for file in Path(directory).rglob(\"*\"):\n",
    "        try:\n",
    "            if file.suffix in [\".pdf\", \".docx\", \".doc\"]:\n",
    "                if file.suffix == \".pdf\":\n",
    "                    text = parse_pdf(file)\n",
    "                else:\n",
    "                    pass\n",
    "                    # For .docx and .doc\n",
    "                    #text = parse_docx(file)\n",
    "\n",
    "                # Extract fields\n",
    "                fields = extract_fields(text)\n",
    "\n",
    "                # Print or save the extracted fields\n",
    "                print(fields)  # Or save to a database/file\n",
    "                \n",
    "                with open(f\"json/{fields.get('name')}.json\", 'w') as file:\n",
    "                   json.dump(fields, file, indent=4)\n",
    "                # # Rename the file\n",
    "                renamed_file_path = rename_file(file, fields.get('name'))\n",
    "                #renamed_file_path = rename_file(file, fields.get('name'))\n",
    "                #renamed_file_path=file\n",
    "                print(f\"Renamed file to: {renamed_file_path}\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "\n",
    "# Example usage\n",
    "process_resumes(\"extracted_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ab3b85-1cad-4cd4-9c67-d8fcd6f94a4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import fitz  # PyMuPDF\n",
    "import docx  # python-docx\n",
    "import requests  # To call the AI API\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3de26d-cf9e-42cb-be0d-bbdd69c98dc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45318af-8f0e-4448-b54f-1284bcb32c24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m118",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m118"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
